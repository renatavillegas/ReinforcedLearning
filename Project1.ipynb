{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf12f58b-cf85-445d-837a-703fef223d96",
   "metadata": {},
   "source": [
    "# MO436A Project1: Reinforced learning algorithms evaluation\n",
    "Nome: Renata Raffaine Villegas RA: 176635 \n",
    "## Problem description \n",
    "Operate in the stock market â€“ buy or sell assets based on historical data. \n",
    "For this project, a stocrastic and a deterministic ambients were built. The ideia is to start with a initial cash and use reinforced lerning to decide if is better to sell the stock, buy more stocks, or hold the money.\n",
    "\n",
    "## MDP Formulation:\n",
    "- States: Current holdings and prices. To make this problem Marcovian, we need to set a window size to keep some prices to help in the inference(buy/sell).\n",
    "- Actions: Buy, Sell, Hold.\n",
    "- Transitions: Price changes\n",
    "- Rewards: The reward is defined by profit/loss of each action\n",
    "- Discount(gamma): long-term gains. \n",
    "\n",
    "Simplfications in the model: \n",
    "- The prices are updated hourly and are updated 10 times a day. \n",
    "- The prices start with the same value each day.\n",
    "- The prices std_dev is constant. \n",
    "- Here we sell/buy all stocks in portifolium, which means it is the same as considering only one stock.\n",
    "\n",
    "Environment characterists: \n",
    "- Episodic - As each day is treated as a complete episode. \n",
    "- Terminal States - There are not terminal states, but we could set one, for example, choose to stop at a maximum profit or maximum lose. \n",
    "- The states are continuous, as they are defined as the price.\n",
    "- The environment is stocrastic as the price vary ramdonly with a normal distribution.\n",
    "- This envrionment is partially observable, as we have information of only a window size of prices. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738737ee-47a3-4bde-80fd-6aea6a544442",
   "metadata": {},
   "source": [
    "## Deterministic environment\n",
    "\n",
    "In this case, the deterministic events means the system might know, given the current price of the stock, what will be the price of the stock in the next hour (next step). The The Rulkov Map is used to generate price movements deterministically, since it can create a \"caotic\" price evolution, mantaining. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a0d2f-eaf1-4ff2-89ae-0eff537f204a",
   "metadata": {},
   "source": [
    "## Stocrastic environment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e29ab-e703-4d03-95d8-a8da501f346c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
